{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniruddh47/AI_DOCTOR/blob/main/AI_DOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWv9ORw6YkgU",
        "outputId": "be457e4c-3883-4c13-8b65-de5594914c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.5798 - loss: 2.1069 - val_accuracy: 0.8346 - val_loss: 0.4872\n",
            "Epoch 2/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.4538 - val_accuracy: 0.8428 - val_loss: 0.4369\n",
            "Epoch 3/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.4072 - val_accuracy: 0.8483 - val_loss: 0.4197\n",
            "Epoch 4/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3843 - val_accuracy: 0.8457 - val_loss: 0.4141\n",
            "Epoch 5/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3742 - val_accuracy: 0.8498 - val_loss: 0.4117\n",
            "Epoch 6/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.3634 - val_accuracy: 0.8504 - val_loss: 0.3992\n",
            "Epoch 7/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.8647 - loss: 0.3508 - val_accuracy: 0.8529 - val_loss: 0.3919\n",
            "Epoch 8/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3454 - val_accuracy: 0.8478 - val_loss: 0.4056\n",
            "Epoch 9/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.3417 - val_accuracy: 0.8498 - val_loss: 0.4006\n",
            "Epoch 10/30\n",
            "\u001b[1m5557/5557\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.3324 - val_accuracy: 0.8509 - val_loss: 0.3984\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.3827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Test Accuracy: 85.31%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 1. Load & clean data\n",
        "df = pd.read_csv(\"/content/Disease and symptoms dataset.csv\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# 2. Separate features and target\n",
        "X = df.drop(\"diseases\", axis=1)\n",
        "y = df[\"diseases\"]\n",
        "\n",
        "# 3. Encode target (diseases)\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Build neural network\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(np.unique(y_encoded)), activation='softmax')  # Output layer for multi-class\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6. Train with epochs & early stopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 7. Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"âœ… Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# 8. Save model and encoder\n",
        "model.save(\"neural_disease_model.h5\")\n",
        "import pickle\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoder, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oppU0gorYmT0"
      },
      "outputs": [],
      "source": [
        "model.save(\"disease_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-ELhKhoCcpr7"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoder, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "29THy2Dycuet"
      },
      "outputs": [],
      "source": [
        "model.save(\"disease_model.keras\")\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoder, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V43liDV1dynk",
        "outputId": "72b2869a-f659-460d-ad8f-e2e8a0590363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
            "ğŸ©º Predicted Disease: panic disorder\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# === Load Trained Model ===\n",
        "model = load_model(\"disease_model.keras\")\n",
        "\n",
        "# === Load Label Encoder ===\n",
        "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
        "    encoder = pickle.load(f)\n",
        "\n",
        "# === Load or Create Input Symptom Vector ===\n",
        "# Replace this vector with actual symptoms in the same format as your training data\n",
        "# 377 binary values: 1 = symptom present, 0 = not\n",
        "# Creating a sample input vector from the first row of the training data X\n",
        "input_vector = X.iloc[0].values.reshape(1, -1) # Assuming X is available from previous cells\n",
        "\n",
        "# === Make Prediction ===\n",
        "prediction = model.predict(input_vector)\n",
        "predicted_label_encoded = np.argmax(prediction, axis=1)\n",
        "predicted_label = encoder.inverse_transform(predicted_label_encoded)\n",
        "\n",
        "print(\"ğŸ©º Predicted Disease:\", predicted_label[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SBsGLTfhShUy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example vector for testing â€” replace with real symptoms\n",
        "symptom_vector = np.zeros(377)\n",
        "symptom_vector[0] = 1  # e.g. anxiety and nervousness\n",
        "symptom_vector[2] = 1  # e.g. shortness of breath\n",
        "symptom_vector[6] = 1  # e.g. insomnia\n",
        "\n",
        "np.save(\"input_vector.npy\", symptom_vector)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR6jqomdTVN5",
        "outputId": "16b5b083-821a-4c2e-fa11-12a6c4d44cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
            "ğŸ©º Predicted Disease: acute stress reaction\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Load model\n",
        "model = load_model(\"/content/disease_model.keras\")\n",
        "\n",
        "# Load encoder\n",
        "with open(\"/content/label_encoder.pkl\", \"rb\") as f:\n",
        "    encoder = pickle.load(f)\n",
        "\n",
        "# Agar input_vector.npy upload kiya hai:\n",
        "input_vector = np.load(\"input_vector.npy\")\n",
        "input_vector = input_vector.reshape(1, -1)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(input_vector)\n",
        "predicted_label = encoder.inverse_transform([np.argmax(pred)])\n",
        "\n",
        "print(\"ğŸ©º Predicted Disease:\", predicted_label[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VXj901YIJW-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e91036-8db2-4446-d028-0e4a6b37736e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Please describe how you're feeling (in one or two sentences):\n",
            "Your description: Your description: I have been coughing a lot and have chest pain with shortness of breath.\n",
            "ğŸ” Detected Symptoms: ['shortness of breath', 'cough']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
            "ğŸ©º Predicted Disease: tietze syndrome\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# === Load Model and Encoder ===\n",
        "model = load_model(\"/content/disease_model.keras\")\n",
        "with open(\"/content/label_encoder.pkl\", \"rb\") as f:\n",
        "    encoder = pickle.load(f)\n",
        "\n",
        "# === Load Dataset to Get Symptom Columns ===\n",
        "df = pd.read_csv(\"/content/Disease and symptoms dataset.csv\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "symptom_columns = df.drop(\"diseases\", axis=1).columns.tolist()\n",
        "\n",
        "# === Get Paragraph from User ===\n",
        "print(\"ğŸ“ Please describe how you're feeling (in one or two sentences):\")\n",
        "paragraph = input(\"Your description: \").lower()\n",
        "\n",
        "# === Extract Matching Symptoms ===\n",
        "found_symptoms = [symptom for symptom in symptom_columns if symptom in paragraph]\n",
        "print(\"ğŸ” Detected Symptoms:\", found_symptoms)\n",
        "\n",
        "# === Create Binary Symptom Vector ===\n",
        "symptom_vector = np.zeros(len(symptom_columns))\n",
        "for i, symptom in enumerate(symptom_columns):\n",
        "    if symptom in found_symptoms:\n",
        "        symptom_vector[i] = 1\n",
        "\n",
        "# === Predict Disease ===\n",
        "input_vector = symptom_vector.reshape(1, -1)\n",
        "pred = model.predict(input_vector)\n",
        "predicted_label = encoder.inverse_transform([np.argmax(pred)])\n",
        "\n",
        "print(\"ğŸ©º Predicted Disease:\", predicted_label[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnGqEBwm8tCq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPdzvY4DD7aro3mV6hEaePh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}